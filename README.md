# M3C2 Point Cloud Processing Pipeline - Refactored

## ğŸ“‹ Ãœbersicht

Dies ist eine vollstÃ¤ndig refactorierte Version der M3C2 Point Cloud Processing Pipeline mit verbesserter Architektur, besserer Testbarkeit und klarer Trennung von Verantwortlichkeiten.

## ğŸ—ï¸ Architektur

Das System folgt einer Clean Architecture mit folgenden Layern:

```
â”œâ”€â”€ domain/              # Business Logic & Entities
â”‚   â”œâ”€â”€ entities.py      # Domain-Objekte (CloudPair, M3C2Parameters, etc.)
â”‚   â”œâ”€â”€ commands/        # Command Pattern fÃ¼r Pipeline-Schritte
â”‚   â”œâ”€â”€ strategies/      # Strategy Pattern fÃ¼r Outlier Detection
â”‚   â”œâ”€â”€ validators/      # Chain of Responsibility fÃ¼r Validierung
â”‚   â””â”€â”€ builders/        # Builder Pattern fÃ¼r Konfiguration
â”‚
â”œâ”€â”€ application/         # Use Cases & Orchestration
â”‚   â”œâ”€â”€ orchestration/   # Pipeline-Orchestrierung
â”‚   â”œâ”€â”€ factories/       # Factories mit Dependency Injection
â”‚   â””â”€â”€ services/        # Application Services
â”‚
â”œâ”€â”€ infrastructure/      # External Dependencies
â”‚   â””â”€â”€ repositories/    # Repository Pattern fÃ¼r Datenzugriff
â”‚
â”œâ”€â”€ presentation/        # UI/CLI/API (noch zu implementieren)
â”‚
â””â”€â”€ shared/             # Cross-cutting Concerns
    â”œâ”€â”€ config_loader.py # Konfiguration
    â””â”€â”€ logging_setup.py # Logging
```

## ğŸš€ Installation

### 1. Virtual Environment erstellen

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# oder
venv\Scripts\activate  # Windows
```

### 2. Dependencies installieren

```bash
pip install -r requirements.txt
```

### 3. Konfiguration anpassen

```bash
cp config_example.json config.json
# Edit config.json nach Bedarf
```

## ğŸ’» Verwendung

### Basis-Verwendung

```bash
python main.py \
    --config config.json \
    --folders Multi-Illumination \
    --project MARS_Multi_Illumination
```

### Mit spezifischen Indizes

```bash
python main.py \
    --config config.json \
    --folders Multi-Illumination \
    --indices 1 2 3 \
    --project MARS_Part1
```

### Nur Statistiken berechnen

```bash
python main.py \
    --config config.json \
    --folders Multi-Illumination \
    --only-stats \
    --use-existing-params
```

### Mit Override-Parametern

```bash
python main.py \
    --config config.json \
    --folders Multi-Illumination \
    --normal-scale 0.002 \
    --search-scale 0.004
```

### Dry-Run Modus

```bash
python main.py \
    --config config.json \
    --folders Multi-Illumination \
    --dry-run
```

## ğŸ“ Dateistruktur

### Eingabe-Struktur

```
data/
â””â”€â”€ Multi-Illumination/
    â”œâ”€â”€ a-1.ply          # Original Part 1, Gruppe A
    â”œâ”€â”€ a-1-AI.ply       # AI-verarbeitet Part 1, Gruppe A
    â”œâ”€â”€ b-1.ply          # Original Part 1, Gruppe B
    â”œâ”€â”€ b-1-AI.ply       # AI-verarbeitet Part 1, Gruppe B
    â””â”€â”€ ...
```

### Ausgabe-Struktur

```
outputs/
â””â”€â”€ MARS_Multi_Illumination_output/
    â”œâ”€â”€ MARS_Multi_Illumination_statistics.xlsx
    â”œâ”€â”€ MARS_Multi_Illumination_plots/
    â”‚   â”œâ”€â”€ part_1_histogram.png
    â”‚   â”œâ”€â”€ part_1_colored.ply
    â”‚   â””â”€â”€ ...
    â””â”€â”€ logs/
        â””â”€â”€ orchestration.log
```

## ğŸ”§ Konfiguration

### Wichtige Konfigurations-Parameter

| Parameter | Beschreibung | Default |
|-----------|--------------|---------|
| `data_path` | Basis-Verzeichnis fÃ¼r Daten | `data` |
| `output_path` | Ausgabe-Verzeichnis | `outputs` |
| `m3c2.normal_scale` | Normal-Radius fÃ¼r M3C2 | Auto-detect |
| `m3c2.search_scale` | Such-Radius fÃ¼r M3C2 | Auto-detect |
| `outlier_detection.method` | Methode fÃ¼r Outlier-Erkennung | `rmse` |
| `outlier_detection.multiplier` | Multiplikator fÃ¼r Threshold | `3.0` |
| `processing.sample_size` | Sample-GrÃ¶ÃŸe fÃ¼r Parameter-SchÃ¤tzung | `10000` |
| `output.format` | Ausgabeformat fÃ¼r Statistiken | `excel` |

## ğŸ§© Design Patterns

### 1. **Repository Pattern**
- Abstrahiert Datenzugriff
- ErmÃ¶glicht einfaches Testen mit Mock-Repositories

### 2. **Command Pattern**
- Jeder Pipeline-Schritt ist ein Command
- ErmÃ¶glicht flexible Pipeline-Komposition

### 3. **Strategy Pattern**
- Verschiedene Outlier-Detection-Strategien
- Einfach erweiterbar mit neuen Methoden

### 4. **Builder Pattern**
- Fluent Interface fÃ¼r Pipeline-Konfiguration
- Validierung beim Build

### 5. **Factory Pattern**
- Service Factory mit Dependency Injection
- Pipeline Factory fÃ¼r Command-Komposition

### 6. **Chain of Responsibility**
- Validatoren kÃ¶nnen verkettet werden
- Jeder Validator prÃ¼ft einen Aspekt

## ğŸ§ª Testing

```bash
# Unit Tests
pytest tests/unit/

# Integration Tests
pytest tests/integration/

# Coverage Report
pytest --cov=. --cov-report=html
```

## ğŸ“Š Erweiterungen

### Neue Outlier-Detection-Methode hinzufÃ¼gen

```python
# domain/strategies/outlier_detection.py
class MyOutlierStrategy(OutlierDetectionStrategy):
    def detect(self, distances: np.ndarray) -> Tuple[np.ndarray, float]:
        # Implementierung
        pass
```

### Neues Command hinzufÃ¼gen

```python
# domain/commands/my_command.py
class MyCommand(Command):
    def execute(self, context: PipelineContext) -> PipelineContext:
        # Implementierung
        pass
    
    def can_execute(self, context: PipelineContext) -> bool:
        # PrÃ¼fung
        pass
```

## ğŸ› Debugging

### Verbose Logging aktivieren

```bash
python main.py --log-level DEBUG
```

### Einzelne Konfiguration testen

```python
from application.factories.service_factory import ServiceFactory
from domain.builders.pipeline_builder import PipelineBuilder

# Setup
config = {...}
factory = ServiceFactory(config)

# Einzelne Konfiguration
builder = PipelineBuilder()
pipeline_config = builder.with_cloud_pair(...).build()

# Test
orchestrator = PipelineOrchestrator(factory)
result = orchestrator.run_single(pipeline_config)
```

## ğŸ“ TODOs fÃ¼r Phase 2-5

- [ ] **Phase 2**: Repository Layer vollstÃ¤ndig implementieren
- [ ] **Phase 3**: Alle Commands implementieren und testen
- [ ] **Phase 4**: Services modularisieren
- [ ] **Phase 5**: Umfassende Tests und Dokumentation

## ğŸ¤ Migration vom alten Code

### Schritt 1: Backup erstellen
```bash
cp -r old_code old_code_backup
```

### Schritt 2: Schrittweise Migration
1. Neue Struktur parallel aufbauen
2. Services einzeln migrieren
3. Tests fÃ¼r jeden migrierten Service
4. Alte Komponenten nach erfolgreicher Migration entfernen

### Schritt 3: Validierung
- Ergebnisse mit altem System vergleichen
- Performance-Tests durchfÃ¼hren
- Edge Cases testen

## ğŸ“š Weitere Dokumentation

- API-Dokumentation: `docs/api/`
- Architektur-Entscheidungen: `docs/adr/`
- Entwickler-Guide: `docs/developer-guide.md`

## ğŸ“„ Lizenz

[Deine Lizenz hier]